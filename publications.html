<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="Bik7o47t8LWfR18eH4FK_fZzR3_xWyOReXlg-WUpm-I" />

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yaniv Yacoby | Publications</title>
    <meta name="author" content="Yaniv Yacoby" />
    <meta name="description" content="Yaniv Yacoby, machine learning researcher and musician based in Boston.
" />
    <meta name="keywords" content="Probabilistic Machine Learning, Uncertainty Quantification, Approximate Inference, Deep Bayesian Models, Latent Variable Models" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê†Ô∏è</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yanivyacoby.github.io/publications">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://yanivyacoby.github.io/">Yaniv Yacoby</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
		
                <a class="nav-link" href="https://mogu-lab.github.io/" target="_blank" rel="noopener noreferrer">Lab</a>
              </li>
              <li class="nav-item active">
		
                <a class="nav-link" href="/publications">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
		
                <a class="nav-link" href="/teaching">Teaching</a>
              </li>
              <li class="nav-item ">
		
                <a class="nav-link" href="/advocacy">Advocacy</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Music</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
		  
                  <a class="dropdown-item" href="/music">Listen &amp; Watch</a>
                  <div class="dropdown-divider"></div>
		  
                  <a class="dropdown-item" href="/performances">Performances</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
      
      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>      
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
	    	    
            <h1 class="post-title">Publications</h1>
	    
	    
            <p class="post-description"></p>
	    
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">

  I served as a direct <strong>research mentor</strong> to the undergraduate/Master's/Ph.D. co-authors whose names are <span style="border-bottom: 1px dashed;">underlined</span>.
  <h2 class="year">2026</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="http://sigcse2026.sigcse.org/" target="_blank" rel="noopener noreferrer">
	       SIGCSE
	  </a></abbr></div>

        <!-- Entry bib key -->
        <div id="yacoby2026teaching" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Teaching Probabilistic Machine Learning in the Liberal Arts: Empowering Socially and Mathematically Informed AI Discourse</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                <em><strong>Y Yacoby</strong></em>
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>SIGCSE</em> 2026

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2510.25049" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a new undergraduate ML course at our institution, a small liberal arts college serving students minoritized in STEM, designed to empower students to critically connect the mathematical foundations of ML with its sociotechnical implications. We propose a "framework-focused" approach, teaching students the language and formalism of probabilistic modeling while leveraging probabilistic programming to lower mathematical barriers. We introduce methodological concepts through a whimsical, yet realistic theme, the "Intergalactic Hypothetical Hospital," to make the content both relevant and accessible. Finally, we pair each technical innovation with counter-narratives that challenge its value using real, open-ended case-studies to cultivate dialectical thinking. By encouraging creativity in modeling and highlighting unresolved ethical challenges, we help students recognize the value and need of their unique perspectives, empowering them to participate confidently in AI discourse as technologists and critical citizens.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2025</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     ICML MOSS
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="liu2025neural" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Neural Stochastic Differential Equations on Compact State-Spaces</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <a href="https://scholar.google.com/citations?user=EfSfs6MAAAAJ&amp;hl=en" class="undergrad" target="_blank" rel="noopener noreferrer">Y Liu</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://www.linkedin.com/in/malindalu/" class="undergrad" target="_blank" rel="noopener noreferrer">M Lu</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://nocklab.fas.harvard.edu/people" target="_blank" rel="noopener noreferrer">M Nock</a>,¬†
	    <!-- Define format for author names -->
	    and <em><strong>Y Yacoby</strong></em>
                
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>ICML MOSS</em> 2025

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2508.17090" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many modern probabilistic models rely on SDEs, but their adoption is hampered by instability, poor inductive bias outside bounded domains, and reliance on restrictive dynamics or training tricks.  While recent work constrains SDEs to compact spaces using reflected dynamics, these approaches lack continuous dynamics and efficient high-order solvers, limiting interpretability and applicability.  We propose a novel class of neural SDEs on compact polyhedral spaces with continuous dynamics, amenable to higher-order solvers, and with favorable inductive bias.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">
	     UAI
	  </abbr><abbr class="badge">
	     ICML HAS
	  </abbr>
</div>

        <!-- Entry bib key -->
        <div id="tadesse2025transparent" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Transparent Trade-offs between Properties of Explanations</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <a href="https://hiwot-belay-tadesse.github.io" class="phd" target="_blank" rel="noopener noreferrer">H Tadesse</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://alihanhyk.github.io" target="_blank" rel="noopener noreferrer">A H√ºy√ºk</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>UAI</em> 2025

	    
	    <br>
	    Previous version accepted @ <em>ICML HAS</em>  2024	    
	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2410.23880v2" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>When explaining machine learning models, it is important for explanations to have certain properties like faithfulness, robustness, smoothness, low complexity, etc. However, many properties are in tension with each other, making it challenging to achieve them simultaneously. For example, reducing the complexity of an explanation can make it less expressive, compromising its faithfulness. The ideal balance of trade-offs between properties tends to vary across different tasks and users. Motivated by these varying needs, we aim to find explanations that make optimal trade-offs while allowing for transparent control over the balance between different properties. Unlike existing methods that encourage desirable properties implicitly through their design, our approach optimizes explanations explicitly for a linear mixture of multiple properties. By adjusting the mixture weights, users can control the balance between those properties and create explanations with precisely what is needed for their particular task.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     Science
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="arens2025preference" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Preference-based Assistance Optimization for Lifting and Lowering with a Soft Back Exosuit</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <span class="phd">P Arens</span>,¬†
	    <!-- Define format for author names -->
	    <span>A Quirk</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://wyss.harvard.edu/team/associate-faculty/conor-walsh/" target="_blank" rel="noopener noreferrer">C Walsh</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>Science Advances</em> 2025

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://www.science.org/doi/10.1126/sciadv.adu2099" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Wearable robotic devices have become increasingly prevalent in both occupational and rehabilitative settings, yet their widespread adoption remains inhibited by usability barriers related to comfort, restriction, and noticeable functional benefits. Acknowledging the importance of user perception in this context, this study explores preference-based controller optimization for a back exosuit that assists lifting. Considering the high mental and metabolic effort discrete motor tasks impose, we used a forced-choice Bayesian Optimization approach that promotes sampling efficiency by leveraging domain knowledge about just noticeable differences between assistance settings. Optimizing over two control parameters, preferred settings were consistent within and uniquely different between participants. We discovered that overall, participants preferred asymmetric parameter configurations with more lifting than lowering assistance, and that preferences were sensitive to user anthropometrics. These findings highlight the potential of perceptually guided assistance optimization for wearable robotic devices, marking a step toward more pervasive adoption of these systems in the real world.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="http://approximateinference.org/" target="_blank" rel="noopener noreferrer">
	       AABI
	  </a></abbr></div>

        <!-- Entry bib key -->
        <div id="yacoby2020mapa" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Towards Model-Agnostic Posterior Approximation for Fast and Accurate Variational Autoencoders</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>Workshop at AABI</em> 2024

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2403.08941" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Inference for Variational Autoencoders (VAEs) consists of learning two models: (1) a generative model, which transforms a simple distribution over a latent space into the distribution over observed data, and (2) an inference model, which approximates the posterior of the latent codes given data. The two components are learned jointly via a lower bound to the generative model‚Äôs log marginal likelihood. In early phases of joint training, the inference model poorly approximates the latent code posteriors. Recent work showed that this leads optimization to get stuck in local optima, negatively impacting the learned generative model. As such, recent work suggests ensuring a high-quality inference model via iterative training: maximizing the objective function relative to the inference model before every update to the generative model. Unfortunately, iterative training is inefficient, requiring heuristic criteria for reverting from iterative to joint training for speed. Here, we suggest an inference method that trains the generative and inference models independently. It approximates the posterior of the true model a priori; fixing this posterior approximation, we then maximize the lower bound relative to only the generative model. By conventional wisdom, this approach should rely on the true prior and likelihood of the true model to approximate its posterior (which are unknown). However, we show that we can compute a deterministic, model-agnostic posterior approximation (MAPA) of the true model‚Äôs posterior. We then use MAPA to develop a proof-of-concept inference method. We present preliminary results on low-dimensional synthetic data that (1) MAPA captures the trend of the true posterior, and (2) our MAPA-based inference performs better density estimation with less computation than baselines. Lastly, we present a roadmap for scaling the MAPA-based inference method to high-dimensional data.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     Nature
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023idiographic" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Building personalized machine learning models using real-time monitoring data to predict idiographic suicidal thoughts</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <a href="https://shirleywang.rbind.io/" target="_blank" rel="noopener noreferrer">S Wang</a>,¬†
	    <!-- Define format for author names -->
	    <span>R Genugten</span>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://depressionmgh.org/who-we-are/staff/kate-bentley-phd" target="_blank" rel="noopener noreferrer">K Bentley</a>,¬†
	    <!-- Define format for author names -->
	    <span>S Bird</span>,¬†
	    <!-- Define format for author names -->
	    <span>R Buonopane</span>,¬†
	    <!-- Define format for author names -->
	    <span>A Christie</span>,¬†
	    <!-- Define format for author names -->
	    <span>M Daniel</span>,¬†
	    <!-- Define format for author names -->
	    <span>D DeMarco</span>,¬†
	    <!-- Define format for author names -->
	    <span>A Haim</span>,¬†
	    <!-- Define format for author names -->
	    <span>L Follet</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://www.rebeccafortgang.com/" target="_blank" rel="noopener noreferrer">R Fortgang</a>,¬†
	    <!-- Define format for author names -->
	    <span>F Kelly</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://kleimanlab.org/people/" target="_blank" rel="noopener noreferrer">E Kleiman</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://alexmillner.com/" target="_blank" rel="noopener noreferrer">A Millner</a>,¬†
	    <!-- Define format for author names -->
	    <span>O Obi-Obasi</span>,¬†
	    <!-- Define format for author names -->
	    <span>J Onnela</span>,¬†
	    <!-- Define format for author names -->
	    <span>N Ramlal</span>,¬†
	    <!-- Define format for author names -->
	    <span>J Ricard</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://smollerlab.org/our-team/" target="_blank" rel="noopener noreferrer">J Smoller</a>,¬†
	    <!-- Define format for author names -->
	    <span>T Tambedou</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://www.kellyzuromski.com/" target="_blank" rel="noopener noreferrer">K Zuromski</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://nocklab.fas.harvard.edu/people" target="_blank" rel="noopener noreferrer">M Nock</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>Nature Mental Health</em> 2024

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://www.nature.com/articles/s44220-024-00335-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Suicide risk is highest immediately after psychiatric hospitalization, but the field lacks methods for identifying which patients are at greatest risk, and when. We built personalized models predicting suicidal thoughts after psychiatric hospital visits (N=89 patients), using ecological momentary assessment (EMA; average EMA responses per participant=311). We built several idiographic models, including baseline autoregressive and elastic net models (using single train/test split) and Gaussian Process (GP) models (using an iterative rolling-forward prediction method). Simple GP models provided the best prediction of suicidal urges (R2_average of 0.17), outperforming baseline autoregressive (R2_average of 0.10) and elastic net (R2_average of 0.07) models. Similarly, simple GP models provided the best prediction of suicidal intent (R2_average of 0.12) compared to autoregressive (R2_average of 0.08) and elastic net (R2_average of 0.06). Findings suggest idiographic prediction of suicidal thoughts is possible, though accuracy currently is modest. Building GP models that iteratively update and learn symptom dynamics over time could provide important information to inform development of just-in-time adaptive interventions.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="http://sigcse2026.sigcse.org/" target="_blank" rel="noopener noreferrer">
	       SIGCSE
	  </a></abbr></div>

        <!-- Entry bib key -->
        <div id="yacoby2023cs290" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Empowering First-Year Computer Science Ph.D. Students to Create a Culture that Values Community and Mental Health</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://scholar.harvard.edu/girash/home" target="_blank" rel="noopener noreferrer">J Girash</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://parkes.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">D Parkes</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>SIGCSE</em> 2023
              <abbr class="badge talk">Oral Presentation</abbr>

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2208.12650" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Doctoral programs often have high rates of depression, anxiety, isolation, and imposter phenomenon. Consequently, graduating students may feel inadequately prepared for research-focused careers, contributing to an attrition of talent. Prior work identifies an important contributing factor to maladjustment: that, even with prior exposure to research, entering Ph.D. students often have problematically idealized views of science. These preconceptions can become obstacles for students in their own professional growth. Unfortunately, existing curricular and extracurricular programming in many doctoral programs do not include mechanisms to systematically address students‚Äô misconceptions of their profession. In this work, we describe a new initiative at our institution that aims to address Ph.D. mental health via a mandatory seminar for entering doctoral students. The seminar is designed to build professional resilience in students by (1) increasing self-regulatory competence, and (2) teaching students to proactively examine academic cultural values, and to participate in shaping them. Our evaluation indicates that students improved in both areas after completing the seminar.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     NeurIPS ICBINB
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="yao2022empirical" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An Empirical Analysis of the Advantages of Finite- vs. Infinite-Width Bayesian Neural Networks</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <a href="https://yaojiayu0826.github.io/" target="_blank" rel="noopener noreferrer">J Yao</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://beaucoker.github.io/" target="_blank" rel="noopener noreferrer">B Coker</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>NeurIPS ICBINB</em> 2022

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2211.09184" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Comparing Bayesian neural networks (BNNs) with different widths is challenging because, as the width increases, multiple model properties change simultaneously, and, inference in the finite-width case is intractable. In this work, we empirically compare finite- and infinite-width BNNs, and provide quantitative and qualitative explanations for their performance difference. We find that when the model is mis-specified, increasing width can hurt BNN performance. In these cases, we provide evidence that finite-width BNNs generalize better partially due to the properties of their frequency spectrum that allows them to adapt under model mismatch.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge"><a href="https://jmlr.org/" target="_blank" rel="noopener noreferrer">
	       JMLR
	  </a></abbr><abbr class="badge">
	     ICML UDL
	  </abbr>
</div>

        <!-- Entry bib key -->
        <div id="yacoby2019mitigating" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Mitigating the Effects of Non-Identifiability on Inference for Bayesian Neural Networks with Latent Variables</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>*Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">*W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>JMLR</em> 2022

	    
	    <br>
	    Previous version accepted @ <em>ICML UDL</em>  2019
              <abbr class="badge talk">Spotlight Talk</abbr>	    
	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/1911.00569" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Bayesian Neural Networks with Latent Variables (BNN+LVs) capture predictive uncertainty by explicitly modeling model uncertainty (via priors on network weights) and environmental stochasticity (via a latent input noise variable). In this work, we first show that BNN+LV suffers from a serious form of non-identifiability: explanatory power can be transferred between the model parameters and latent variables while fitting the data equally well. We demonstrate that as a result, in the limit of infinite data, the posterior mode over the network weights and latent variables is asymptotically biased away from the ground-truth. Due to this asymptotic bias, traditional inference methods may in practice yield parameters that generalize poorly and misestimate uncertainty. Next, we develop a novel inference procedure that explicitly mitigates the effects of likelihood non-identifiability during training and yields high-quality predictions as well as uncertainty estimates. We demonstrate that our inference method improves upon benchmark methods across a range of synthetic and real data-sets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge"><a href="https://www.humancomputation.com/" target="_blank" rel="noopener noreferrer">
	       HCOMP
	  </a></abbr><abbr class="badge"><a href="https://hcxai.jimdosite.com/" target="_blank" rel="noopener noreferrer">
	       CHI HCXAI
	  </a></abbr>
</div>

        <!-- Entry bib key -->
        <div id="yacoby2022psa" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">"If it didn‚Äôt happen, why would I change my decision?": How Judges Respond to Counterfactual Explanations for the Public Safety Assessment</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://www.benzevgreen.com/" target="_blank" rel="noopener noreferrer">B Green</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://law.arizona.edu/christopher-l-griffin-jr" target="_blank" rel="noopener noreferrer">C Griffin</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>HCOMP</em> 2022

	    
	    <br>
	    Previous version accepted @ <em>CHI HCXAI</em>  2022
              <abbr class="badge talk">Oral Presentation</abbr>	    
	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2205.05424" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many researchers and policymakers have expressed excitement about algorithmic explanations enabling more fair and responsible decision-making. However, recent experimental studies have found that explanations do not always improve human use of algorithmic advice. In this study, we shed light on how people interpret and respond to counterfactual explanations (CFEs) ‚Äì explanations that show how a model‚Äôs output would change with marginal changes to its input(s) ‚Äì in the context of pretrial risk assessment instruments (PRAIs). We ran think-aloud trials with eight sitting U.S. state court judges, providing them with recommendations from a PRAI that includes CFEs. We found that the CFEs did not alter the judges‚Äô decisions. At first, judges misinterpreted the counterfactuals as real ‚Äì rather than hypothetical ‚Äì changes to defendants. Once judges understood what the counterfactuals meant, they ignored them, stating their role is only to make decisions regarding the actual defendant in question. The judges also expressed a mix of reasons for ignoring or following the advice of the PRAI without CFEs. These results add to the literature detailing the unexpected ways in which people respond to algorithms and explanations. They also highlight new challenges associated with improving human-algorithm collaborations through explanations.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">
	     arXiv
	  </abbr><abbr class="badge">
	     ICML UDL
	  </abbr>
</div>

        <!-- Entry bib key -->
        <div id="yacoby2020failure" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Failure Modes of Variational Autoencoders and Their Effects on Downstream Tasks</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Full paper on  <em>arXiv</em> 2022

	    
	    <br>
	    Previous version accepted @ <em>ICML UDL</em>  2020	    
	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2007.07124" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Variational Auto-encoders (VAEs) are deep generative latent variable models that are widely used for a number of downstream tasks. While it has been demonstrated that VAE training can suffer from a number of pathologies, existing literature lacks characterizations of exactly when these pathologies occur and how they impact downstream task performance. In this paper, we concretely characterize conditions under which VAE training exhibits pathologies and connect these failure modes to undesirable effects on specific downstream tasks, such as learning compressed and disentangled representations, adversarial robustness, and semi-supervised learning.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">
	     arXiv
	  </abbr><abbr class="badge">
	     ICML UDL
	  </abbr>
</div>

        <!-- Entry bib key -->
        <div id="thakur2020uncertainty" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Uncertainty-Aware (UNA) Bases for Deep Bayesian Regression Using Multi-Headed Auxiliary Networks</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <span class="masters">*S Thakur</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://scholar.google.com/citations?user=eHR-sX0AAAAJ&amp;hl=en" class="masters" target="_blank" rel="noopener noreferrer">*C Lorsung</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>*Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Full paper on  <em>arXiv</em> 2022

	    
	    <br>
	    Previous version accepted @ <em>ICML UDL</em>  2020	    
	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2006.11695" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural Linear Models (NLM) are deep Bayesian models that produce predictive uncertainties by learning features from the data and then performing Bayesian linear regression over these features. Despite their popularity, few works have focused on methodically evaluating the predictive uncertainties of these models. In this work, we demonstrate that traditional training procedures for NLMs drastically underestimate uncertainty on out-of-distribution inputs, and that they therefore cannot be naively deployed in risk-sensitive applications. We identify the underlying reasons for this behavior and propose a novel training framework that captures useful predictive uncertainties for downstream tasks.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     ICML UDL
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="guenais2020bacoun" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">BACOUN: Bayesian Classifiers with Out-of-Distribution Uncertainty</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <span class="masters">T Gu√©nais</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://dvamvourellis.github.io/" class="masters" target="_blank" rel="noopener noreferrer">D Vamvourellis</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>ICML UDL</em> 2020

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2007.06096" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Traditional training of deep classifiers yields overconfident models that are not reliable under dataset shift. We propose a Bayesian framework to obtain reliable uncertainty estimates for deep classifiers. Our approach consists of a plug-in "generator" used to augment the data with an additional class of points that lie on the boundary of the training data, followed by Bayesian inference on top of features that are trained to distinguish these "out-of-distribution" points.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     ICML WHI
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="downs2020cruds" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">CRUDS: Counterfactual Recourse using Disentangled Subspaces</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <span class="masters">M Downs</span>,¬†
	    <!-- Define format for author names -->
	    <span class="undergrad">J Chu</span>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>ICML WHI</em> 2020

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://oconnell.fas.harvard.edu/files/finale/files/cruds-_counterfactual_recourse_using_disentangled_subspaces.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Algorithmic recourse is the task of generating a set of actions that will allow individuals to achieve a more favorable outcome under a given algorithmic decision system. Using the Conditional Subspace Variational Autoencoder (CSVAE), we propose a novel algorithmic recourse generation method, CRUDS, that generates multiple recourse satisfying underlying structure of the data as well as end-user specified constraints. We evaluate our method qualitatively and quantitatively on several synthetic and real datasets, demonstrating that CRUDS proposes recourse that are more realistic and actionable than baselines.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge"><a href="http://approximateinference.org/" target="_blank" rel="noopener noreferrer">
	       AABI
	  </a></abbr><abbr class="badge"><a href="https://proceedings.mlr.press/" target="_blank" rel="noopener noreferrer">
	       PMLR
	  </a></abbr>
</div>

        <!-- Entry bib key -->
        <div id="yacoby2020characterizing" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Characterizing and Avoiding Problematic Global Optima of Variational Autoencoders</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>AABI</em> 2019
              <abbr class="badge talk">Spotlight Talk</abbr>

	    
          </div>

          	  
          <div class="periodical">
	    Additionally selected for publication @ <em>PMLR</em> 2019 <abbr class="badge talk">Top 33%</abbr>
	  </div>
          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2003.07756" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Variational Auto-encoders (VAEs) are deep generative latent variable models consisting of two components: a generative model that captures a data distribution p(x) by transforming a distribution p(z) over latent space, and an inference model that infers likely latent codes for each data point. Recent work shows that traditional training methods tend to yield solutions that violate modeling desiderata: (1) the learned generative model captures the observed data distribution but does so while ignoring the latent codes, resulting in codes that do not represent the data; (2) the aggregate of the learned latent codes does not match the prior p(z). This mismatch means that the learned generative model will be unable to generate realistic data with samples from p(z). In this paper, we demonstrate that both issues stem from the fact that the global optima of the VAE training objective often correspond to undesirable solutions. Our analysis builds on two observations: (1) the generative model is unidentifiable - there exist many generative models that explain the data equally well, each with different (and potentially unwanted) properties and (2) bias in the VAE objective - the VAE objective may prefer generative models that explain the data poorly but have posteriors that are easy to approximate. We present a novel inference method, LiBI, mitigating the problems identified in our analysis. On synthetic datasets, we show that LiBI can learn generative models that capture the data distribution and inference models that better satisfy modeling assumptions when traditional methods struggle to do so.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">
	     ASRM
	  </abbr></div>

        <!-- Entry bib key -->
        <div id="vaughan2019application" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">The application of machine learning methods to evaluate predictors of live birth in programmed thaw cycles</div>
          <!-- Author -->
          <div class="author">
	    <!-- Define format for author names -->
	    <a href="https://www.bostonivf.com/our-practice/physicians/DenisVaughan/" target="_blank" rel="noopener noreferrer">D Vaughan</a>,¬†
	    <!-- Define format for author names -->
	    <a href="https://onefishy.github.io/" target="_blank" rel="noopener noreferrer">W Pan</a>,¬†
	    <!-- Define format for author names -->
	    
                  <em><strong>Y Yacoby</strong></em>,¬†
	    <!-- Define format for author names -->
	    <a href="https://www.bostonivf.com/our-practice/physicians/EmilySeidler/" target="_blank" rel="noopener noreferrer">E Seidler</a>,¬†
	    <!-- Define format for author names -->
	    <span>A Leung</span>,¬†
	    <!-- Define format for author names -->
	    <a href="https://finale.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">F Doshi-Velez</a>,¬†
	    <!-- Define format for author names -->
	    and <a href="https://www.bostonivf.com/our-practice/fertility-lab-research/DennySakkas/" target="_blank" rel="noopener noreferrer">D Sakkas</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- Workshop title and date -->
	  	  
	  
          <div class="periodical">
             Accepted @  <em>Fertility and Sterility</em> 2019

	    
          </div>

          
          
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://finale.seas.harvard.edu/files/finale/files/the_application_of_machine_learning_methods_to_evaluate_predictors_for_live_birth_in_programmed_thaw_cycles.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>	    
          </div>

          
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container" style="text-align: center;">
        ¬© Copyright 2025 <a href="/">Yaniv  Yacoby</a>. Adapted from the <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

      </div>
    </footer>


    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KB54ZTDTNF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-KB54ZTDTNF');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </body>
</html>

